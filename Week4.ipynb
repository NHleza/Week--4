{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNxRxetKPWa0tTm5Ri7Uskq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NHleza/Week--4/blob/main/Week4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARt64KBjNusQ"
      },
      "outputs": [],
      "source": [
        "# Week 4 Assignment: AI in Software Engineering\n",
        "# Theme: \"Building Intelligent Software Solutions\" ðŸ’»ðŸ¤–\n",
        "\n",
        "# Import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.metrics import classification_report, mean_squared_error\n",
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy import displacy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# -----------------------------\n",
        "# Part 1: Automated Bug Detection (Classification)\n",
        "# -----------------------------\n",
        "\n",
        "# Synthetic dataset simulating code metrics and bug presence\n",
        "# Features: lines_of_code, cyclomatic_complexity, num_functions, num_comments\n",
        "# Target: bug_present (0 = no bug, 1 = bug)\n",
        "data = {\n",
        "    'lines_of_code': [100, 250, 150, 300, 400, 120, 500, 350, 200, 450],\n",
        "    'cyclomatic_complexity': [10, 25, 15, 30, 40, 12, 50, 35, 20, 45],\n",
        "    'num_functions': [5, 12, 7, 15, 20, 6, 25, 18, 10, 22],\n",
        "    'num_comments': [20, 30, 25, 35, 40, 22, 45, 38, 28, 42],\n",
        "    'bug_present': [0, 1, 0, 1, 1, 0, 1, 1, 0, 1]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split dataset\n",
        "X = df.drop('bug_present', axis=1)\n",
        "y = df['bug_present']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Bug Detection Classification Report:\\n\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# -----------------------------\n",
        "# Part 2: Code Optimization Suggestion (Regression)\n",
        "# -----------------------------\n",
        "\n",
        "# Synthetic dataset simulating code metrics and execution time (ms)\n",
        "data_opt = {\n",
        "    'lines_of_code': [100, 250, 150, 300, 400, 120, 500, 350, 200, 450],\n",
        "    'cyclomatic_complexity': [10, 25, 15, 30, 40, 12, 50, 35, 20, 45],\n",
        "    'num_functions': [5, 12, 7, 15, 20, 6, 25, 18, 10, 22],\n",
        "    'execution_time_ms': [120, 350, 180, 400, 500, 130, 600, 450, 200, 550]\n",
        "}\n",
        "\n",
        "df_opt = pd.DataFrame(data_opt)\n",
        "\n",
        "# Features and target\n",
        "X_opt = df_opt.drop('execution_time_ms', axis=1)\n",
        "y_opt = df_opt['execution_time_ms']\n",
        "\n",
        "# Split dataset\n",
        "X_train_opt, X_test_opt, y_train_opt, y_test_opt = train_test_split(X_opt, y_opt, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "reg.fit(X_train_opt, y_train_opt)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_opt = reg.predict(X_test_opt)\n",
        "mse = mean_squared_error(y_test_opt, y_pred_opt)\n",
        "print(f\"\\nCode Execution Time Prediction MSE: {mse:.2f}\")\n",
        "\n",
        "# Plot actual vs predicted execution times\n",
        "plt.scatter(y_test_opt, y_pred_opt)\n",
        "plt.xlabel(\"Actual Execution Time (ms)\")\n",
        "plt.ylabel(\"Predicted Execution Time (ms)\")\n",
        "plt.title(\"Code Execution Time Prediction\")\n",
        "plt.plot([min(y_test_opt), max(y_test_opt)], [min(y_test_opt), max(y_test_opt)], 'r--')\n",
        "plt.show()\n",
        "\n",
        "# -----------------------------\n",
        "# Part 3: NLP for Code Comment Summarization using spaCy\n",
        "# -----------------------------\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# code comment\n",
        "comment = \"\"\"\n",
        "This function calculates the factorial of a number recursively.\n",
        "It multiplies the number by the factorial of the number minus one until it reaches one.\n",
        "\"\"\"\n",
        "\n",
        "# Process comment\n",
        "doc = nlp(comment)\n",
        "\n",
        "# Extract noun chunks and verbs as a simple summary heuristic\n",
        "nouns = [chunk.text for chunk in doc.noun_chunks if chunk.text.lower() not in STOP_WORDS]\n",
        "verbs = [token.lemma_ for token in doc if token.pos_ == \"VERB\"]\n",
        "\n",
        "summary = \"Summary: \" + \", \".join(nouns) + \". Key actions: \" + \", \".join(set(verbs)) + \".\"\n",
        "\n",
        "print(\"\\nCode Comment Summary:\")\n",
        "print(summary)\n",
        "\n",
        "# Visualize named entities if any (for demonstration)\n",
        "displacy.render(doc, style=\"ent\")\n",
        "\n",
        "# -----------------------------\n",
        "# Ethical Reflection (to include in report)\n",
        "# -----------------------------\n",
        "\n",
        "\"\"\"\n",
        "Ethical Reflection:\n",
        "\n",
        "- Automated bug detection and code optimization models must be trained on diverse, representative datasets to avoid bias toward certain coding styles or languages.\n",
        "- Transparency in AI decision-making is essential, especially when AI suggests code changes that impact software behavior.\n",
        "- Privacy of proprietary codebases must be maintained when using AI tools, ensuring data is securely handled.\n",
        "- AI should augment developersâ€™ expertise, not replace human judgment, to maintain software quality and accountability.\n",
        "- Continuous monitoring and validation of AI models are required to prevent performance degradation and unintended consequences.\n",
        "\"\"\"\n",
        "\n",
        "# End of notebook\n"
      ]
    }
  ]
}